# üëÅÔ∏è‚Äçüó®Ô∏è Nvidia CUDA 

<img src="https://img.shields.io/badge/Numba-3.10.7-00A3E0?style=flat&logo=Numba&logoColor=white"> <img src="https://img.shields.io/badge/NumPy-3.10.7-00A3E0?style=flat&logo=numpy&logoColor=white"> <img src="https://img.shields.io/badge/Anaconda-3.10.7-44A833?style=flat&logo=Anaconda&logoColor=white"> <img src="https://img.shields.io/badge/CUDA-3.10.7-76B900?style=flat&logo=nvidia&logoColor=white">

<img src="https://upload.wikimedia.org/wikipedia/en/b/b9/Nvidia_CUDA_Logo.jpg" align="right" height="77">

O **Nvidia CUDA** √© uma plataforma de computa√ß√£o paralela e um modelo de programa√ß√£o para ser usado com GPUs - Unidade de Processamento Gr√°fica. Com ele, toda a parte ‚Äúpesada‚Äù do c√≥digo √© executada nos diversos n√∫cleos da placa de v√≠deo enquanto apenas a parte sequencial do c√≥digo √© executada no processador, obtendo um ganho significativo de performance.

> **CUDA** anteriormente conhecida como Arquitetura de Dispositivo de Computa√ß√£o Unificada √© uma API destinada a computa√ß√£o paralela.

> O uso da GPU tem custos indiretos. Se o c√°lculo n√£o for pesado o suficiente, o custo (em tempo) de usar uma GPU pode ser maior do que o ganho. Por outro lado, se o c√°lculo for pesado, voc√™ pode ver uma grande melhoria na velocidade.

V√°rios termos importantes no t√≥pico de programa√ß√£o CUDA est√£o listados aqui:

- Host: a CPU
- Device: a GPU
- Host memory: a mem√≥ria principal do sistema
- Device memory: mem√≥ria integrada em um cart√£o GPU
- Kernel: uma fun√ß√£o GPU lan√ßada pelo host e executada no dispositivo
- Device function: uma fun√ß√£o GPU executada no dispositivo que s√≥ pode ser chamada a partir do dispositivo (ou seja, a partir de um kernel ou outra fun√ß√£o do dispositivo).

<img src="https://upload.wikimedia.org/wikipedia/commons/f/fe/Numba_logo.svg" height="77" align="right">

O **Numba** oferece suporte √† programa√ß√£o de GPU CUDA compilando diretamente um subconjunto restrito de c√≥digo Python em kernels CUDA e fun√ß√µes de dispositivo seguindo o modelo de execu√ß√£o CUDA. Kernels escritos em Numba parecem ter acesso direto aos arrays **NumPy**. Matrizes NumPy s√£o transferidas entre a CPU e a GPU automaticamente. Numba funciona permitindo que voc√™ especifique assinaturas de tipo para fun√ß√µes Python, o que permite a compila√ß√£o em tempo de execu√ß√£o (isto √©, ‚ÄúJust-in-Time‚Äù ou compila√ß√£o JIT).

> **Numba** √© um projeto de c√≥digo aberto, licenciado por BSD, que se baseia fortemente nas capacidades do compilador LLVM.

**Exemplo**: O decorador `@vectorize`, no c√≥digo a seguir, gera uma vers√£o compilada e vetorizada da fun√ß√£o escalar em tempo de execu√ß√£o para que possa ser usada para processar matrizes de dados em paralelo na GPU.

```python
import numpy as np
from numba import vectorize

@vectorize(['float32(float32, float32)'], target='cuda')
def Add(a, b):
return a + b

# Initialize arrays
N = 100000
A = np.ones(N, dtype=np.float32)
B = np.ones(A.shape, dtype=A.dtype)
C = np.empty_like(A, dtype=A.dtype)

# Add arrays on GPU
C = Add(A, B)
```

<img src="https://www.svgrepo.com/show/354127/numpy.svg" height="77" align="right">

Para compilar e executar a mesma fun√ß√£o na CPU, simplesmente mudamos o destino para 'cpu', o que produz desempenho no n√≠vel do c√≥digo C vetorizado e compilado na CPU. Essa flexibilidade ajuda a produzir c√≥digo mais reutiliz√°vel e permite desenvolver em m√°quinas sem GPUs.

> Um dos pontos fortes da plataforma de computa√ß√£o paralela CUDA √© a variedade de bibliotecas aceleradas por GPUs dispon√≠veis.

Outro projeto da equipe Numba, chamado **pyculib**, fornece uma interface Python para as bibliotecas CUDA cuBLAS (√°lgebra linear densa), cuFFT (Fast Fourier Transform) e cuRAND (gera√ß√£o de n√∫mero aleat√≥rio).

Muitos aplicativos ser√£o capazes de obter uma acelera√ß√£o significativa apenas usando essas bibliotecas, sem escrever nenhum c√≥digo espec√≠fico da GPU. Por exemplo, o c√≥digo a seguir gera um milh√£o de n√∫meros aleat√≥rios uniformemente distribu√≠dos na GPU usando o gerador de n√∫meros pseudoaleat√≥rios ‚ÄúXORWOW‚Äù.

```python
import numpy as np
from pyculib import rand as curand

prng = curand.PRNG(rndtype=curand.PRNG.XORWOW)
rand = np.empty(100000)
prng.uniform(rand)
print rand[:10]
```

<img src="https://anaconda.org/static/img/anaconda-symbol.svg" height="77" align="right">

A capacidade do Numba de compilar c√≥digo dinamicamente significa que voc√™ n√£o abre m√£o da flexibilidade do Python. Esse √© um grande passo para fornecer a combina√ß√£o ideal de programa√ß√£o de alta produtividade e computa√ß√£o de alto desempenho.

O back-end da GPU do Numba utiliza o NVIDIA Compiler SDK baseado em LLVM. Os wrappers pyculib em torno das bibliotecas CUDA tamb√©m s√£o de c√≥digo aberto e licenciados por BSD.

Para come√ßar a usar o Numba, a primeira etapa √© baixar e instalar a distribui√ß√£o **Anaconda Python**, uma "distribui√ß√£o Python totalmente gratuita, pronta para empresas, para processamento de dados em grande escala, an√°lise preditiva e computa√ß√£o cient√≠fica" que inclui muitos pacotes populares (Numpy, SciPy, Matplotlib, IPython etc).

Digite o comando para baixar o Numba:

```sh
apt-get install libgl1-mesa-glx libegl1-mesa libxrandr2 libxrandr2 libxss1 libxcursor1 libxcomposite1 libasound2 libxi6 libxtst6
```

Agora, voc√™ pode ativar a instala√ß√£o, fazendo um source no arquivo `~/.bashrc: source ~/.bashrc`

Assim que tiver feito isso, voc√™ ser√° levado ao ambiente de programa√ß√£o padr√£o de base do Anaconda, e seu prompt de comando mudar√° para o seguinte: `(base) summy@ubuntu:~$`

Embora o Anaconda venha com esse ambiente de programa√ß√£o padr√£o de base, voc√™ deve criar ambientes separados para seus programas e mant√™-los isolados um do outro. Voc√™ pode, ainda, verificar sua instala√ß√£o fazendo o uso do comando `conda`, por exemplo, com `list`:

```sh
conda list
```

Voc√™ receber√° a sa√≠da de todos os pacotes dispon√≠veis atrav√©s da instala√ß√£o do Anaconda.

<pre>
# packages in environment at /home/sammy/anaconda3:
# Name                    Version                  Build  Channel
_ipyw_jlab_nb_ext_conf    0.1.0                    py37_0
_libgcc_mutex             0.1                        main
alabaster                 0.7.12                   py37_0
anaconda                  2020.02                  py37_0
...
</pre>

Agora que o Anaconda est√° instalado, podemos seguir em frente para a configura√ß√£o dos ambientes dele.

> **Aten√ß√£o**: Os ambientes virtuais do Anaconda lhe permitem manter projetos organizados pelas vers√µes do Python e pelos pacotes necess√°rios. Para cada ambiente do Anaconda que voc√™ configurar, especifique qual vers√£o do Python usar e mantenha todos os arquivos de programa√ß√£o relacionados dentro desse diret√≥rio.

Primeiro, podemos verificar quais vers√µes do Python est√£o dispon√≠veis para que possamos usar: `conda search "^python$"`

> Vamos criar um ambiente usando a vers√£o mais recente do Python 3.

Podemos conseguir isso atribuindo a vers√£o 3 ao argumento python. Vamos chamar o ambiente de `my_env`, mas voc√™ pode usar um nome mais descritivo para o ambiente, especialmente se estiver usando ambientes para acessar mais de uma vers√£o do Python.

```sh
conda create --name my_env python=3
```

Voc√™ receber√° uma sa√≠da com informa√ß√µes sobre o que est√° baixado e quais pacotes ser√£o instalados e, em seguida, ser√° solicitado a prosseguir com `y` ou `n`. Assim que concordar, digite `y`.

O utilit√°rio `conda` agora ir√° obter os pacotes para o ambiente e inform√°-lo assim que estiver conclu√≠do. Voc√™ pode ativar seu novo ambiente digitando o seguinte:

```sh
conda activate my_env
```

Com seu ambiente ativado, seu prefixo do prompt de comando ir√° refletir que voc√™ n√£o est√° mais no ambiente base, mas no novo ambiente que acabou de criar.

<pre>
(my_env) summy@ubuntu:~$
</pre>

Dentro do ambiente, voc√™ pode verificar se est√° usando a vers√£o do Python que tinha inten√ß√£o de usar: `(my_env) summy@ubuntu:~$ python ‚Äìversion`

Quando estiver pronto para desativar seu ambiente do Anaconda, voc√™ pode fazer isso digitando: `(my_env) summy@ubuntu:~$ conda deactivate`

Observe que pode substituir a palavra source por `.` para obter os mesmos resultados. Para focar em uma vers√£o mais espec√≠fica do Python, voc√™ pode passar uma vers√£o espec√≠fica para o argumento python, como 3.5, por exemplo:

```sh
conda create -n my_env35 python=3.5
```

Voc√™ pode inspecionar todos os ambientes que configurou com este comando:

<pre>
(base) summy@ubuntu:~$ conda info ‚Äìenvs


# conda environments:
#
base                  *  /home/sammy/anaconda3
my_env                   /home/sammy/anaconda3/envs/my_env
my_env35                 /home/sammy/anaconda3/envs/my_env35
</pre>

O asterisco indica o ambiente ativo atual. Cada ambiente que voc√™ criar com o `conda create` vir√° com v√°rios pacotes padr√£o:

- `_libgcc_mutex`
- `ca-certificates`
- `certifi`
- `libedit`
- `libffi`
- `libgcc-ng`
- `libstdcxx-ng`
- `ncurses`
- `openssl`
- `pip`
- `python`
- `readline`
- `setuptools`
- `sqlite`
- `tk`
- `wheel`
- `xz`
- `zlib`

Voc√™ pode acrescentar pacotes adicionais, como o Numpy, por exemplo, com o seguinte comando:

```sh
conda install --name my_env35 numpy
```

Se voc√™ j√° sabe que gostaria de um ambiente Numpy ap√≥s a cria√ß√£o, pode concentr√°-lo em seu comando `conda create`:

```sh
conda create --name my_env python=3 numpy
```

Se voc√™ n√£o estiver mais trabalhando em um projeto espec√≠fico e n√£o tiver mais necessidade do ambiente associado, pode remov√™-lo. Para fazer isso, digite o seguinte:

```sh
conda remove --name my_env35 --all
```

> **Aten√ß√£o**: Agora, quando voc√™ digitar o comando `conda info --envs`, o ambiente que removeu n√£o ser√° mais listado.

Voc√™ deve garantir regularmente que o Anaconda esteja atualizado para que voc√™ esteja trabalhando com todas as vers√µes mais recentes do pacote. Para fazer isso, deve primeiro atualizar o utilit√°rio conda: `(base) summy@ubuntu:~$ conda update conda`

Quando solicitado a fazer isso, digite `y` para continuar com a atualiza√ß√£o. Assim que a atualiza√ß√£o do `conda` estiver conclu√≠da, voc√™ pode atualizar a distribui√ß√£o do Anaconda:

```sh
conda update anaconda
```

> **Aten√ß√£o**: Novamente, quando solicitado a fazer isso, digite `y` para continuar. Isso garantir√° que voc√™ esteja usando as vers√µes mais recentes do `conda` e do Anaconda.

Depois de instalar o Anaconda, instale os pacotes CUDA necess√°rios digitando:

```sh
conda install numba cudatoolkit pyculib
```

> O **Anaconda** (anteriormente Continuum Analytics) reconheceu que alcan√ßar grandes acelera√ß√µes em alguns c√°lculos requer uma interface de programa√ß√£o mais expressiva com controle mais detalhado sobre o paralelismo do que as bibliotecas e a vetoriza√ß√£o autom√°tica de `loop` podem fornecer.
>
> Portanto, o Numba possui outro conjunto importante de recursos que constitui o que √© conhecido n√£o oficialmente como ‚ÄúCUDA Python‚Äù.

Numba exp√µe o modelo de programa√ß√£o CUDA, assim como em CUDA C / C ++, mas usando a sintaxe Python pura, para que os programadores possam criar kernels paralelos personalizados e ajustados sem deixar o conforto e as vantagens do Python para tr√°s. O CUDA JIT da Numba (dispon√≠vel via decorador ou chamada de fun√ß√£o) compila fun√ß√µes CUDA Python em tempo de execu√ß√£o, especializando-as para os tipos que voc√™ usa, e sua API CUDA Python fornece controle expl√≠cito sobre transfer√™ncias de dados e fluxos CUDA, entre outros recursos.

O exemplo de c√≥digo a seguir demonstra isso com um kernel de conjunto Mandelbrot simples. Observe que a fun√ß√£o `mandel_kernel` usa as estruturas `cuda.threadIdx`, `cuda.blockIdx`, `cuda.blockDim` e `cuda.gridDim` fornecidas por Numba para calcular os √≠ndices globais de pixel `X` e `Y` para o segmento atual. Como em outras linguagens CUDA, lan√ßamos o kernel inserindo uma "configura√ß√£o de execu√ß√£o" (linguagem CUDA para o n√∫mero de threads e blocos de threads a serem usados para executar o kernel) entre colchetes, entre o nome da fun√ß√£o e a lista de argumentos: `mandel_kernel` [griddim, blockdim] (- 2.0, 1.0, -1.0, 1.0, d_image, 20). Voc√™ tamb√©m pode ver o uso das fun√ß√µes de API `to_host` e `to_device` para copiar dados de e para a GPU.

```python
@cuda.jit
def mandel_kernel(min_x, max_x, min_y, max_y, image, iters):
	height = image.shape[0]
	width = image.shape[1]

	pixel_size_x = (max_x - min_x) / width
	pixel_size_y = (max_y - min_y) / height

	startX = cuda.blockDim.x * cuda.blockIdx.x + cuda.threadIdx.x
	startY = cuda.blockDim.y * cuda.blockIdx.y + cuda.threadIdx.y
	gridX = cuda.gridDim.x * cuda.blockDim.x;
	gridY = cuda.gridDim.y * cuda.blockDim.y;

	for x in range(startX, width, gridX):
		real = min_x + x * pixel_size_x
		for y in range(startY, height, gridY):
			imag = min_y + y * pixel_size_y
			image[y, x] = mandel(real, imag, iters)

	gimage = np.zeros((1024, 1536), dtype = np.uint8)
	blockdim = (32, 8)
	griddim = (32,16)

	start = timer()
	d_image = cuda.to_device(gimage)
	mandel_kernel[griddim, blockdim](-2.0, 1.0, -1.0, 1.0, d_image, 20)
	d_image.to_host()
	dt = timer() - start

	print "Mandelbrot created on GPU in %f s" % dt

	imshow(gimage)
```

> Em um servidor com uma GPU NVIDIA Tesla P100 e uma CPU Intel Xeon E5-2698 v3, este c√≥digo CUDA Python Mandelbrot √© executado quase 1700 vezes mais r√°pido do que a vers√£o Python pura. 1700x pode parecer uma acelera√ß√£o irreal, mas tenha em mente que estamos comparando o c√≥digo Python compilado, paralelo e acelerado por GPU ao c√≥digo Python interpretado de thread √∫nico na CPU.
